{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Image Modality Encoder\n",
    "class ImageVAEEncoder(nn.Module):\n",
    "    def __init__(self, input_channels=1, latent_dim=256):\n",
    "        super(ImageVAEEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(in_features=64 * 28 * 28, out_features=latent_dim)\n",
    "        self.fc_logvar = nn.Linear(in_features=64 * 28 * 28, out_features=latent_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.flatten(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "    \n",
    "    \n",
    "\n",
    "# Image Modality Decoder\n",
    "class ImageVAEDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=256, output_channels=1):\n",
    "        super(ImageVAEDecoder, self).__init__()\n",
    "        self.fc = nn.Linear(in_features=latent_dim, out_features=64 * 28 * 28)\n",
    "        self.convtrans1 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convtrans2 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convtrans3 = nn.ConvTranspose2d(16, output_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc(z)\n",
    "        z = z.view(-1, 64, 28, 28)\n",
    "        z = self.relu(self.convtrans1(z))\n",
    "        z = self.relu(self.convtrans2(z))\n",
    "        z = self.output_activation(self.convtrans3(z))\n",
    "        return z\n",
    "\n",
    "# ECG Modality Encoder\n",
    "class ECGVAEEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=60000, latent_dim=256):\n",
    "        super(ECGVAEEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(in_features=64 * (input_dim // 8), out_features=latent_dim)  # Adjusted for stride=2, 3 layers\n",
    "        self.fc_logvar = nn.Linear(in_features=64 * (input_dim // 8), out_features=latent_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.flatten(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "# ECG Modality Decoder\n",
    "class ECGVAEDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=256, output_dim=60000):\n",
    "        super(ECGVAEDecoder, self).__init__()\n",
    "        self.fc = nn.Linear(in_features=latent_dim, out_features=64 * (output_dim // 8))\n",
    "        self.convtrans1 = nn.ConvTranspose1d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convtrans2 = nn.ConvTranspose1d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convtrans3 = nn.ConvTranspose1d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_activation = nn.Identity()  # Suitable for standardized data\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc(z)\n",
    "        z = z.view(-1, 64, z.size(1) // 64)  # Adjust the reshape for proper dimensions\n",
    "        z = self.relu(self.convtrans1(z))\n",
    "        z = self.relu(self.convtrans2(z))\n",
    "        z = self.output_activation(self.convtrans3(z))\n",
    "        return z\n",
    "\n",
    "class MVAE(nn.Module):\n",
    "    def __init__(self, image_encoder, ecg_encoder, image_decoder, ecg_decoder, latent_dim=256, num_classes=2):\n",
    "        super(MVAE, self).__init__()\n",
    "        self.image_encoder = image_encoder\n",
    "        self.ecg_encoder = ecg_encoder\n",
    "        self.image_decoder = image_decoder\n",
    "        self.ecg_decoder = ecg_decoder\n",
    "\n",
    "        # Classification layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, 512),  # Latent dimensions from both encoders are concatenated\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, xray, ecg):\n",
    "        xray_mu, xray_logvar = self.image_encoder(xray)\n",
    "        ecg_mu, ecg_logvar = self.ecg_encoder(ecg)\n",
    "\n",
    "        # Sample from the latent spaces\n",
    "        xray_z = self.reparameterize(xray_mu, xray_logvar)\n",
    "        ecg_z = self.reparameterize(ecg_mu, ecg_logvar)\n",
    "\n",
    "        # Concatenate the latent representations\n",
    "        combined_z = torch.cat([xray_z, ecg_z], dim=1)\n",
    "\n",
    "        # Classification\n",
    "        prediction = self.classifier(combined_z)\n",
    "\n",
    "        # Optionally, decode the combined representation back into the original modalities\n",
    "        reconstructed_xray = self.image_decoder(xray_z)\n",
    "        reconstructed_ecg = self.ecg_decoder(ecg_z)\n",
    "\n",
    "        return prediction, reconstructed_xray, reconstructed_ecg\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T19:55:56.547148400Z",
     "start_time": "2024-03-02T19:55:55.206997600Z"
    }
   },
   "id": "6a524abd5e2c92d9",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pydicom\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Loop through each label directory\n",
    "        for label in [0, 1]:\n",
    "            label_dir = os.path.join(root_dir, f'processed_label_{label}')\n",
    "            for folder_name in os.listdir(label_dir):\n",
    "                folder_path = os.path.join(label_dir, folder_name)\n",
    "                image_name = os.listdir(folder_path)[0]  # Assuming only one image per folder\n",
    "                if image_name.endswith('.jpg'):\n",
    "                    self.images.append(os.path.join(folder_path, image_name))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    " \n",
    "# Initialize your dataset\n",
    "xray_dataset = XRayDataset(root_dir='D:/Aspire_xray/xray', transform=transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.ToTensor(),\n",
    "]))\n",
    "\n",
    "\n",
    "def process_dicom(file_path, sampling_rate=500):\n",
    "    desired_length = 10 * sampling_rate  # 10 seconds of data\n",
    "    try:\n",
    "        dicom_data = pydicom.dcmread(file_path)\n",
    "        if \"WaveformSequence\" in dicom_data:\n",
    "            rhythm_waveform = dicom_data.WaveformSequence[1]\n",
    "            wave_data = rhythm_waveform.get(\"WaveformData\")\n",
    "            num_channels = rhythm_waveform.NumberOfWaveformChannels\n",
    "            wave_array = np.frombuffer(wave_data, dtype=np.int16)\n",
    "            num_samples_per_channel = wave_array.size // num_channels\n",
    "            \n",
    "            if wave_array.size % num_channels == 0:\n",
    "                wave_array = wave_array.reshape(num_samples_per_channel, num_channels)\n",
    "                \n",
    "\n",
    "                # Trim or Pad the array to 10 seconds\n",
    "                if wave_array.shape[0] > desired_length:\n",
    "                    wave_array = wave_array[:desired_length, :]\n",
    "                elif wave_array.shape[0] < desired_length:\n",
    "                    padding = np.zeros((desired_length - wave_array.shape[0], num_channels), dtype=wave_array.dtype)\n",
    "                    wave_array = np.vstack((wave_array, padding))\n",
    "                \n",
    "                # Normalize the array\n",
    "                wave_array = (wave_array - np.mean(wave_array, axis=0)) / np.std(wave_array, axis=0)\n",
    "\n",
    "                return wave_array\n",
    "            else:\n",
    "                print(f\"Unexpected data size in {file_path}. Skipping file.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"No Waveform data found in {file_path}. Skipping file.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.ecg_data = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Loop through each label directory\n",
    "        for label in [0, 1]:\n",
    "            label_dir = os.path.join(root_dir, f'processed_label_{label}')\n",
    "            for folder_name in os.listdir(label_dir):\n",
    "                folder_path = os.path.join(label_dir, folder_name)\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    if file_name.endswith('.dcm'):\n",
    "                        file_path = os.path.join(folder_path, file_name)\n",
    "                        ecg_waveform = process_dicom(file_path)\n",
    "                        if ecg_waveform is not None:\n",
    "                            self.ecg_data.append(ecg_waveform)\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ecg_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ecg_waveform = self.ecg_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Reshape waveform to [1, signal_length]\n",
    "        ecg_waveform = ecg_waveform.reshape(1, -1)  \n",
    "        return torch.tensor(ecg_waveform, dtype=torch.float32), label\n",
    "\n",
    "# Usage example\n",
    "ecg_dataset = ECGDataset(root_dir='D:/Aspire_ecg/ecg')\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, xray_dataset, ecg_dataset):\n",
    "        self.xray_dataset = xray_dataset\n",
    "        self.ecg_dataset = ecg_dataset\n",
    "        assert len(xray_dataset) == len(ecg_dataset), \"Datasets must be of the same length.\"\n",
    "        \n",
    "        # Assuming the labels are the same for both datasets and can be directly accessed\n",
    "        self.labels = [label for _, label in xray_dataset]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xray_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xray_image, xray_label = self.xray_dataset[idx]\n",
    "        ecg_waveform, ecg_label = self.ecg_dataset[idx]\n",
    "        \n",
    "        # Ensure the labels match if they are supposed to be the same\n",
    "        assert xray_label == ecg_label, \"Labels do not match for the same index.\"\n",
    "        \n",
    "        return xray_image, ecg_waveform, xray_label  # Use either xray_label or ecg_label\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "# Instantiate the combined dataset\n",
    "combined_dataset = CombinedDataset(xray_dataset, ecg_dataset)\n",
    "labels = combined_dataset.get_labels()\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-02T19:56:43.065810300Z",
     "start_time": "2024-03-02T19:56:21.662692400Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7372 ± 0.0554\n",
      "Accuracy: 0.7249 ± 0.0457\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import random \n",
    "import numpy as np\n",
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set a seed value\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "# Model instantiation for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "latent_dim = 256\n",
    "num_classes = 2  # Assuming binary classification for PAWP prediction\n",
    "\n",
    "image_encoder = ImageVAEEncoder(input_channels=1, latent_dim=latent_dim).to(device)\n",
    "ecg_encoder = ECGVAEEncoder(input_dim=60000, latent_dim=latent_dim).to(device)\n",
    "image_decoder = ImageVAEDecoder(latent_dim=latent_dim, output_channels=1).to(device)\n",
    "ecg_decoder = ECGVAEDecoder(latent_dim=latent_dim, output_dim=60000).to(device)\n",
    "\n",
    "classification_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, loss_fn, num_epochs=10):\n",
    "    best_auc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for xray_images, ecg_waveforms, labels in train_loader:\n",
    "            xray_images = xray_images.to(device)\n",
    "            ecg_waveforms = ecg_waveforms.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions, _, _ = model(xray_images, ecg_waveforms)\n",
    "            loss = loss_fn(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for xray_images, ecg_waveforms, labels in val_loader:\n",
    "                xray_images = xray_images.to(device)\n",
    "                ecg_waveforms = ecg_waveforms.to(device)\n",
    "                \n",
    "                predictions, _, _ = model(xray_images, ecg_waveforms)\n",
    "                all_predictions.append(predictions.cpu().numpy())\n",
    "                all_labels.append(labels.numpy())  # Labels are used on CPU for metric calculation\n",
    "        \n",
    "        all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        \n",
    "        # Convert softmax outputs to binary predictions for AUC calculation\n",
    "        binary_predictions = all_predictions[:, 1]  # Assuming class 1 is the positive class\n",
    "        \n",
    "        # Calculate AUC and accuracy\n",
    "        auc = roc_auc_score(all_labels, binary_predictions)\n",
    "        accuracy = accuracy_score(all_labels, np.argmax(all_predictions, axis=1))\n",
    "        \n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            # Save the best model, adjust as needed\n",
    "    \n",
    "    return auc, accuracy\n",
    "\n",
    "# Assuming combined_dataset is defined\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "dataset_size = len(combined_dataset)\n",
    "indices = np.arange(dataset_size)\n",
    "labels = np.array(combined_dataset.get_labels())\n",
    "\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(indices, labels):\n",
    "    train_subset = Subset(combined_dataset, train_index)\n",
    "    val_subset = Subset(combined_dataset, test_index)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    model = MVAE(image_encoder, ecg_encoder, image_decoder, ecg_decoder, latent_dim=256, num_classes=num_classes).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    auc, accuracy = train_and_evaluate(model, train_loader, val_loader, optimizer, loss_fn, num_epochs=10)\n",
    "    auc_scores.append(auc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "print(f\"AUC: {mean_auc:.4f} ± {std_auc:.4f}\")\n",
    "print(f\"Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T12:06:08.559131500Z",
     "start_time": "2024-03-03T12:06:08.544585300Z"
    }
   },
   "id": "217e9258a942f94b",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "CNN Xray (without pretrained)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20b7a0666caf0074"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Loop through each label directory\n",
    "        for label in [0, 1]:\n",
    "            label_dir = os.path.join(root_dir, f'processed_label_{label}')\n",
    "            for folder_name in os.listdir(label_dir):\n",
    "                folder_path = os.path.join(label_dir, folder_name)\n",
    "                image_name = os.listdir(folder_path)[0]  # Assuming only one image per folder\n",
    "                if image_name.endswith('.jpg'):\n",
    "                    self.images.append(os.path.join(folder_path, image_name))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    " \n",
    "# Initialize your dataset\n",
    "xray_dataset = XRayDataset(root_dir='D:/Aspire_xray/xray', transform=transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.ToTensor(),\n",
    "]))"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-07T13:30:33.380564600Z",
     "start_time": "2024-06-07T13:30:33.330308300Z"
    }
   },
   "id": "initial_id",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.675, STD: 0.03\n",
      "Mean AUC: 0.638, STD: 0.06\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "# CNN classifier model\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=2):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 256)  # Adjust the input features according to your image size\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        logits = self.fc2(x)\n",
    "        return logits\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            logits = model(images)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    auc_score = roc_auc_score(all_labels, all_probs)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return accuracy, auc_score\n",
    "\n",
    "# Training loop\n",
    "def train_classifier(model, train_loader, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "# Start of the cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(skf.split(np.zeros(len(xray_dataset)), xray_dataset.labels)):\n",
    "\n",
    "    train_subset = Subset(xray_dataset, train_ids)\n",
    "    test_subset = Subset(xray_dataset, test_ids)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=32)\n",
    "\n",
    "    model = CNNClassifier(input_channels=1, num_classes=2).to('cuda')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_classifier(model, train_loader, criterion, optimizer, epochs=50)\n",
    "\n",
    "    accuracy, auc_score = evaluate_model(model, test_loader)\n",
    "    fold_results.append((accuracy, auc_score))\n",
    "\n",
    "# Calculate mean and STD for each metric across folds\n",
    "accuracies, aucs = zip(*fold_results)\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "mean_auc = np.mean(aucs)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "print(f'Mean Accuracy: {mean_accuracy:.3f}, STD: {std_accuracy:.3f}')\n",
    "print(f'Mean AUC: {mean_auc:.3f}, STD: {std_auc:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T13:32:28.841786100Z",
     "start_time": "2024-06-07T13:32:28.813227500Z"
    }
   },
   "id": "7e81895f0c4ea9d5",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "ECG only (without pretrained)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eab699b573816ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.signal\n",
    "\n",
    "def process_dicom(file_path, sampling_rate=500):\n",
    "    desired_length = 10 * sampling_rate  # 10 seconds of data\n",
    "    try:\n",
    "        dicom_data = pydicom.dcmread(file_path)\n",
    "        if \"WaveformSequence\" in dicom_data:\n",
    "            rhythm_waveform = dicom_data.WaveformSequence[1]\n",
    "            wave_data = rhythm_waveform.get(\"WaveformData\")\n",
    "            num_channels = rhythm_waveform.NumberOfWaveformChannels\n",
    "            wave_array = np.frombuffer(wave_data, dtype=np.int16)\n",
    "            num_samples_per_channel = wave_array.size // num_channels\n",
    "            \n",
    "            if wave_array.size % num_channels == 0:\n",
    "                wave_array = wave_array.reshape(num_samples_per_channel, num_channels)\n",
    "                \n",
    "\n",
    "                # Trim or Pad the array to 10 seconds\n",
    "                if wave_array.shape[0] > desired_length:\n",
    "                    wave_array = wave_array[:desired_length, :]\n",
    "                elif wave_array.shape[0] < desired_length:\n",
    "                    padding = np.zeros((desired_length - wave_array.shape[0], num_channels), dtype=wave_array.dtype)\n",
    "                    wave_array = np.vstack((wave_array, padding))\n",
    "                \n",
    "                # Normalize the array\n",
    "                wave_array = (wave_array - np.mean(wave_array, axis=0)) / np.std(wave_array, axis=0)\n",
    "\n",
    "                return wave_array\n",
    "            else:\n",
    "                print(f\"Unexpected data size in {file_path}. Skipping file.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"No Waveform data found in {file_path}. Skipping file.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.ecg_data = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Loop through each label directory\n",
    "        for label in [0, 1]:\n",
    "            label_dir = os.path.join(root_dir, f'processed_label_{label}')\n",
    "            for folder_name in os.listdir(label_dir):\n",
    "                folder_path = os.path.join(label_dir, folder_name)\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    if file_name.endswith('.dcm'):\n",
    "                        file_path = os.path.join(folder_path, file_name)\n",
    "                        ecg_waveform = process_dicom(file_path)\n",
    "                        if ecg_waveform is not None:\n",
    "                            self.ecg_data.append(ecg_waveform)\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ecg_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ecg_waveform = self.ecg_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Reshape waveform to [1, signal_length]\n",
    "        ecg_waveform = ecg_waveform.reshape(1, -1)  \n",
    "        return torch.tensor(ecg_waveform, dtype=torch.float32), label\n",
    "\n",
    "# Usage example\n",
    "ecg_dataset = ECGDataset(root_dir='D:/Aspire_ecg/ecg')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T13:32:57.460931700Z",
     "start_time": "2024-06-07T13:32:54.003628300Z"
    }
   },
   "id": "75d12abd0fc3e416",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.707, STD: 0.05\n",
      "Mean AUC: 0.724, STD: 0.05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, matthews_corrcoef\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)  # Added third convolutional layer\n",
    "        # Adjust the linear layer input size based on the output size of the last conv layer\n",
    "        self.fc1 = nn.Linear(64 * 7500, 128)  # Adjusted for the output size before flattening\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(self.relu(self.conv1(x)))\n",
    "        x = self.maxpool(self.relu(self.conv2(x)))\n",
    "        x = self.maxpool(self.relu(self.conv3(x)))  # Pass through the third conv layer\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Set a seed value\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "mcc_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(np.zeros(len(ecg_dataset)), ecg_dataset.labels)):\n",
    "\n",
    "    train_subset = Subset(ecg_dataset, train_idx)\n",
    "    test_subset = Subset(ecg_dataset, test_idx)\n",
    "\n",
    "    trainloader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    testloader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "    classifier = CNNClassifier(num_classes=2)  # Adjust 'num_classes' if necessary\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        classifier.train()\n",
    "        for ecg_data, labels in trainloader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = classifier(ecg_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    classifier.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ecg_data, labels in testloader:\n",
    "\n",
    "            outputs = classifier(ecg_data)\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            probas = torch.softmax(outputs, dim=1)[:, 1]\n",
    "\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            probabilities.extend(probas.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    fold_accuracy = accuracy_score(true_labels, predictions)\n",
    "    fold_auc = roc_auc_score(true_labels, probabilities)\n",
    "\n",
    "    accuracy_scores.append(fold_accuracy)\n",
    "    auc_scores.append(fold_auc)\n",
    "\n",
    "\n",
    "average_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "print(f'Average AUC: {average_auc:.3f}, Std Dev: {std_auc:.3f}')\n",
    "print(f'Average Accuracy: {average_accuracy:.3f}, Std Dev: {std_accuracy:.3f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T13:34:00.198231200Z",
     "start_time": "2024-06-07T13:34:00.170778400Z"
    }
   },
   "id": "82ea47e213eb7c1b",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Xray + ECG (Without pretraining)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cbf49058ee5a76"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pydicom\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Loop through each label directory\n",
    "        for label in [0, 1]:\n",
    "            label_dir = os.path.join(root_dir, f'processed_label_{label}')\n",
    "            for folder_name in os.listdir(label_dir):\n",
    "                folder_path = os.path.join(label_dir, folder_name)\n",
    "                image_name = os.listdir(folder_path)[0]  # Assuming only one image per folder\n",
    "                if image_name.endswith('.jpg'):\n",
    "                    self.images.append(os.path.join(folder_path, image_name))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    " \n",
    "# Initialize your dataset\n",
    "xray_dataset = XRayDataset(root_dir='D:/Aspire_xray/xray', transform=transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.ToTensor(),\n",
    "]))\n",
    "\n",
    "\n",
    "def process_dicom(file_path, sampling_rate=500):\n",
    "    desired_length = 10 * sampling_rate  # 10 seconds of data\n",
    "    try:\n",
    "        dicom_data = pydicom.dcmread(file_path)\n",
    "        if \"WaveformSequence\" in dicom_data:\n",
    "            rhythm_waveform = dicom_data.WaveformSequence[1]\n",
    "            wave_data = rhythm_waveform.get(\"WaveformData\")\n",
    "            num_channels = rhythm_waveform.NumberOfWaveformChannels\n",
    "            wave_array = np.frombuffer(wave_data, dtype=np.int16)\n",
    "            num_samples_per_channel = wave_array.size // num_channels\n",
    "            \n",
    "            if wave_array.size % num_channels == 0:\n",
    "                wave_array = wave_array.reshape(num_samples_per_channel, num_channels)\n",
    "                \n",
    "\n",
    "                # Trim or Pad the array to 10 seconds\n",
    "                if wave_array.shape[0] > desired_length:\n",
    "                    wave_array = wave_array[:desired_length, :]\n",
    "                elif wave_array.shape[0] < desired_length:\n",
    "                    padding = np.zeros((desired_length - wave_array.shape[0], num_channels), dtype=wave_array.dtype)\n",
    "                    wave_array = np.vstack((wave_array, padding))\n",
    "                \n",
    "                # Normalize the array\n",
    "                wave_array = (wave_array - np.mean(wave_array, axis=0)) / np.std(wave_array, axis=0)\n",
    "\n",
    "                return wave_array\n",
    "            else:\n",
    "                print(f\"Unexpected data size in {file_path}. Skipping file.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"No Waveform data found in {file_path}. Skipping file.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.ecg_data = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Loop through each label directory\n",
    "        for label in [0, 1]:\n",
    "            label_dir = os.path.join(root_dir, f'processed_label_{label}')\n",
    "            for folder_name in os.listdir(label_dir):\n",
    "                folder_path = os.path.join(label_dir, folder_name)\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    if file_name.endswith('.dcm'):\n",
    "                        file_path = os.path.join(folder_path, file_name)\n",
    "                        ecg_waveform = process_dicom(file_path)\n",
    "                        if ecg_waveform is not None:\n",
    "                            self.ecg_data.append(ecg_waveform)\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ecg_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ecg_waveform = self.ecg_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Reshape waveform to [1, signal_length]\n",
    "        ecg_waveform = ecg_waveform.reshape(1, -1)  \n",
    "        return torch.tensor(ecg_waveform, dtype=torch.float32), label\n",
    "\n",
    "# Usage example\n",
    "ecg_dataset = ECGDataset(root_dir='D:/Aspire_ecg/ecg')\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, xray_dataset, ecg_dataset):\n",
    "        self.xray_dataset = xray_dataset\n",
    "        self.ecg_dataset = ecg_dataset\n",
    "        assert len(xray_dataset) == len(ecg_dataset), \"Datasets must be of the same length.\"\n",
    "        \n",
    "        # Assuming the labels are the same for both datasets and can be directly accessed\n",
    "        self.labels = [label for _, label in xray_dataset]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xray_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xray_image, xray_label = self.xray_dataset[idx]\n",
    "        ecg_waveform, ecg_label = self.ecg_dataset[idx]\n",
    "        \n",
    "        # Ensure the labels match if they are supposed to be the same\n",
    "        assert xray_label == ecg_label, \"Labels do not match for the same index.\"\n",
    "        \n",
    "        return xray_image, ecg_waveform, xray_label  # Use either xray_label or ecg_label\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "# Instantiate the combined dataset\n",
    "combined_dataset = CombinedDataset(xray_dataset, ecg_dataset)\n",
    "labels = combined_dataset.get_labels()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T13:34:46.944725200Z",
     "start_time": "2024-06-07T13:34:24.756200700Z"
    }
   },
   "id": "5e302b344337744e",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CombinedCNNClassifier(nn.Module):\n",
    "    def __init__(self, xray_input_channels=1, ecg_input_channels=1, num_classes=2):\n",
    "        super(CombinedCNNClassifier, self).__init__()\n",
    "        # X-ray branch (similar to CNNClassifier for X-ray)\n",
    "        self.xray_conv1 = nn.Conv2d(xray_input_channels, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.xray_conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.xray_conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.xray_flatten = nn.Flatten()\n",
    "        self.xray_fc = nn.Linear(64 * 28 * 28, 256)  # Adjust according to your X-ray image size\n",
    "\n",
    "        # ECG branch (similar to CNNClassifier for ECG)\n",
    "        self.ecg_conv1 = nn.Conv1d(ecg_input_channels, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.ecg_conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.ecg_conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.ecg_maxpool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.ecg_flatten = nn.Flatten()\n",
    "        self.ecg_fc = nn.Linear(64 * 7500, 128)  # Adjust according to your ECG signal length\n",
    "\n",
    "        # Combined layers\n",
    "        self.combined_fc1 = nn.Linear(256 + 128, 128)  # Combine features from both modalities\n",
    "        self.combined_fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, xray, ecg):\n",
    "        # X-ray branch\n",
    "        xray = self.relu(self.xray_conv1(xray))\n",
    "        xray = self.relu(self.xray_conv2(xray))\n",
    "        xray = self.relu(self.xray_conv3(xray))\n",
    "        xray = self.xray_flatten(xray)\n",
    "        xray_features = self.relu(self.xray_fc(xray))\n",
    "\n",
    "        # ECG branch\n",
    "        ecg = self.ecg_maxpool(self.relu(self.ecg_conv1(ecg)))\n",
    "        ecg = self.ecg_maxpool(self.relu(self.ecg_conv2(ecg)))\n",
    "        ecg = self.ecg_maxpool(self.relu(self.ecg_conv3(ecg)))\n",
    "        ecg = self.ecg_flatten(ecg)\n",
    "        ecg_features = self.relu(self.ecg_fc(ecg))\n",
    "\n",
    "        # Combine features\n",
    "        combined_features = torch.cat((xray_features, ecg_features), dim=1)\n",
    "        combined_features = self.dropout(self.relu(self.combined_fc1(combined_features)))\n",
    "        logits = self.combined_fc2(combined_features)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T13:34:46.951818200Z",
     "start_time": "2024-06-07T13:34:46.944725200Z"
    }
   },
   "id": "cc32c2884bb499d1",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=50):\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for xray_images, ecg_signals, labels in train_loader:\n",
    "            xray_images, ecg_signals, labels = xray_images.to(device), ecg_signals.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(xray_images, ecg_signals)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * xray_images.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xray_images, ecg_signals, labels in test_loader:\n",
    "            xray_images, ecg_signals, labels = xray_images.to(device), ecg_signals.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(xray_images, ecg_signals)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    auc_score = roc_auc_score(all_labels, all_probs)\n",
    "    return accuracy, auc_score\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T13:34:46.961343900Z",
     "start_time": "2024-06-07T13:34:46.947833900Z"
    }
   },
   "id": "bc55cda0fb94637f",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.735, STD: 0.039\n",
      "Mean AUC: 0.748, STD: 0.053\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(skf.split(np.zeros(len(combined_dataset)), combined_dataset.labels)):\n",
    "    \n",
    "    # Splitting the dataset\n",
    "    train_subset = Subset(combined_dataset, train_ids)\n",
    "    test_subset = Subset(combined_dataset, test_ids)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=32)\n",
    "    \n",
    "    # Model initialization\n",
    "    model = CombinedCNNClassifier().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    train_model(model, train_loader, criterion, optimizer, epochs=50)\n",
    "    \n",
    "    # Evaluation\n",
    "    accuracy, auc_score = evaluate_model(model, test_loader)\n",
    "    fold_results.append((accuracy, auc_score))\n",
    "\n",
    "# Calculate mean and STD for each metric across folds\n",
    "accuracies, aucs = zip(*fold_results)\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "mean_auc = np.mean(aucs)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "print(f'Mean Accuracy: {mean_accuracy:.3f}, STD: {std_accuracy:.3f}')\n",
    "print(f'Mean AUC: {mean_auc:.3f}, STD: {std_auc:.3f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T13:36:48.908734800Z",
     "start_time": "2024-06-07T13:36:48.892024Z"
    }
   },
   "id": "c97e25f757325c28",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

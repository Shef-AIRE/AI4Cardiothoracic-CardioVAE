{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-10T15:51:00.532540400Z",
     "start_time": "2024-01-10T15:50:57.593575100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "file_path = 'Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-2.0.0-metadata_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows where 'PatientOrientationCodeSequence_CodeMeaning' is 'Erect'\n",
    "df = df[df['PatientOrientationCodeSequence_CodeMeaning'] == 'Erect']\n",
    "\n",
    "# Further filter rows where 'ViewPosition' is 'PA'\n",
    "df = df[df['ViewPosition'] == 'PA']\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "df.to_csv('Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic_cxr_metadata.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification successful: Both CSVs have the same unique subject_ids.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the original CSV files\n",
    "cxr_file_path = 'Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/filtered_mimic_cxr_metadata_with_no_missing_files.csv'\n",
    "ecg_file_path = 'Z:/tale2/Shared/Mohammod/mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0/filtered_mimic_ecg_metadata_no_missing_files.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "cxr_df = pd.read_csv(cxr_file_path)\n",
    "ecg_df = pd.read_csv(ecg_file_path)\n",
    "\n",
    "# Convert 'subject_id' to int (if not already)\n",
    "cxr_df['subject_id'] = cxr_df['subject_id'].astype(int)\n",
    "ecg_df['subject_id'] = ecg_df['subject_id'].astype(int)\n",
    "\n",
    "# Find common 'subject_id's\n",
    "common_subject_ids = set(cxr_df['subject_id']).intersection(set(ecg_df['subject_id']))\n",
    "\n",
    "# Filter the DataFrames\n",
    "filtered_cxr_df = cxr_df[cxr_df['subject_id'].isin(common_subject_ids)]\n",
    "filtered_ecg_df = ecg_df[ecg_df['subject_id'].isin(common_subject_ids)]\n",
    "\n",
    "# Save the filtered DataFrames to new CSV files\n",
    "filtered_cxr_df.to_csv('filtered_mimic_cxr_metadata.csv', index=False)\n",
    "filtered_ecg_df.to_csv('filtered_mimic_ecg_metadata.csv', index=False)\n",
    "\n",
    "# Verification step\n",
    "# Reload the filtered CSVs and check if they have the same unique subject_ids\n",
    "reloaded_cxr_df = pd.read_csv('filtered_mimic_cxr_metadata.csv')\n",
    "reloaded_ecg_df = pd.read_csv('filtered_mimic_ecg_metadata.csv')\n",
    "\n",
    "# Verify if both have the same unique subject_ids\n",
    "if set(reloaded_cxr_df['subject_id']) == set(reloaded_ecg_df['subject_id']):\n",
    "    print(\"Verification successful: Both CSVs have the same unique subject_ids.\")\n",
    "else:\n",
    "    print(\"Verification failed: The CSVs do not have the same unique subject_ids.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T16:20:45.304595700Z",
     "start_time": "2024-01-11T16:20:43.842230200Z"
    }
   },
   "id": "9cae2b9e09652610"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique subject_ids in MIMIC-CXR: 26220\n",
      "Unique subject_ids in MIMIC-ECG: 26220\n",
      "Number of rows in balanced MIMIC-CXR dataset: 53724\n",
      "Number of rows in balanced MIMIC-ECG dataset: 239465\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the MIMIC-CXR and MIMIC-ECG CSV files\n",
    "# Replace these with the actual file paths\n",
    "cxr_file_path = 'filtered_mimic_cxr_metadata.csv'\n",
    "ecg_file_path = 'filtered_mimic_ecg_metadata.csv'\n",
    "\n",
    "# Read the MIMIC-CXR CSV file\n",
    "cxr_df = pd.read_csv(cxr_file_path)\n",
    "# Count the unique subject_ids in the MIMIC-CXR file\n",
    "unique_subjects_cxr = cxr_df['subject_id'].nunique()\n",
    "print(f\"Unique subject_ids in MIMIC-CXR: {unique_subjects_cxr}\")\n",
    "\n",
    "# Read the MIMIC-ECG CSV file\n",
    "ecg_df = pd.read_csv(ecg_file_path)\n",
    "# Count the unique subject_ids in the MIMIC-ECG file\n",
    "unique_subjects_ecg = ecg_df['subject_id'].nunique()\n",
    "print(f\"Unique subject_ids in MIMIC-ECG: {unique_subjects_ecg}\")\n",
    "\n",
    "\n",
    "# Count the number of rows in each DataFrame\n",
    "num_rows_cxr = cxr_df.shape[0]\n",
    "num_rows_ecg = ecg_df.shape[0]\n",
    "\n",
    "print(f\"Number of rows in balanced MIMIC-CXR dataset: {num_rows_cxr}\")\n",
    "print(f\"Number of rows in balanced MIMIC-ECG dataset: {num_rows_ecg}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T16:20:52.072237100Z",
     "start_time": "2024-01-11T16:20:51.791332100Z"
    }
   },
   "id": "2f247c51354c48dc"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved with the new 'file_path' column.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = 'filtered_mimic_cxr_metadata.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Create the 'file_path' column with prefixes\n",
    "df['file_path'] = df.apply(lambda row: f\"files/p{row['subject_id']}/s{row['study_id']}/{row['dicom_id']}.jpg\", axis=1)\n",
    "\n",
    "# Save the DataFrame back to CSV\n",
    "output_file = 'Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/filtered_mimic_cxr_metadata_with_path.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"CSV file saved with the new 'file_path' column.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T15:48:06.501840700Z",
     "start_time": "2024-01-11T15:48:05.255920Z"
    }
   },
   "id": "1bb10c8cab7ca8f3"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing files (rows being removed): 946\n",
      "CSV file saved with missing files removed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = 'Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/filtered_mimic_cxr_metadata_with_path.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Root directory\n",
    "root = 'Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/'\n",
    "\n",
    "# Identify indices of rows with missing files\n",
    "missing_file_indices = df[~df['file_path'].apply(lambda x: os.path.exists(os.path.join(root, x)))].index\n",
    "\n",
    "# Print the number of missing files\n",
    "print(f\"Number of missing files (rows being removed): {len(missing_file_indices)}\")\n",
    "\n",
    "# Remove rows with missing files\n",
    "df.drop(missing_file_indices, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "output_csv_file = 'Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/filtered_mimic_cxr_metadata_with_no_missing_files.csv'\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(\"CSV file saved with missing files removed.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T15:53:02.774650600Z",
     "start_time": "2024-01-11T15:51:54.624625500Z"
    }
   },
   "id": "e53f3889c3f7c612"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing files (rows being removed): 74148\n",
      "CSV file saved with missing files removed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = 'filtered_mimic_ecg_metadata.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Root directory\n",
    "root = 'Z:/tale2/Shared/Mohammod/mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0'\n",
    "\n",
    "# Identify indices of rows with missing files\n",
    "missing_file_indices = df[~df['path'].apply(lambda x: os.path.exists(os.path.join(root, x + '.dat')))].index\n",
    "\n",
    "# Print the number of missing files\n",
    "print(f\"Number of missing files (rows being removed): {len(missing_file_indices)}\")\n",
    "\n",
    "# Remove rows with missing files\n",
    "df.drop(missing_file_indices, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "output_csv_file = 'Z:/tale2/Shared/Mohammod/mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0/filtered_mimic_ecg_metadata_no_missing_files.csv'\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(\"CSV file saved with missing files removed.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T16:11:32.680576900Z",
     "start_time": "2024-01-11T15:53:34.240708200Z"
    }
   },
   "id": "cff3c76a76021ecc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = 'Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/filtered_mimic_cxr_metadata_with_no_missing_files.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Root directory\n",
    "root = 'Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/'\n",
    "\n",
    "# Count the number of files that are not found\n",
    "missing_files_count = 0\n",
    "\n",
    "# Check each file\n",
    "for file_path in df['path']:\n",
    "    # Append the .dat extension to the file path\n",
    "    full_path = os.path.join(root, file_path)\n",
    "    if not os.path.exists(full_path):\n",
    "        missing_files_count += 1\n",
    "\n",
    "print(f\"Number of missing files: {missing_files_count}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aab4b84af17e8177"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in balanced MIMIC-CXR dataset: 50981\n",
      "Number of rows in balanced MIMIC-ECG dataset: 50981\n",
      "Balancing complete. Balanced datasets saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "cxr_file_path = 'filtered_mimic_cxr_metadata.csv'\n",
    "ecg_file_path = 'filtered_mimic_ecg_metadata.csv'\n",
    "\n",
    "cxr_df = pd.read_csv(cxr_file_path)\n",
    "ecg_df = pd.read_csv(ecg_file_path)\n",
    "\n",
    "# Ensure 'subject_id' is int\n",
    "cxr_df['subject_id'] = cxr_df['subject_id'].astype(int)\n",
    "ecg_df['subject_id'] = ecg_df['subject_id'].astype(int)\n",
    "\n",
    "# Getting unique subject_ids\n",
    "subject_ids = cxr_df['subject_id'].unique()\n",
    "\n",
    "# Lists to store balanced data\n",
    "balanced_cxr_data = []\n",
    "balanced_ecg_data = []\n",
    "\n",
    "for subject_id in subject_ids:\n",
    "    # Filter rows for the current subject_id\n",
    "    cxr_rows = cxr_df[cxr_df['subject_id'] == subject_id]\n",
    "    ecg_rows = ecg_df[ecg_df['subject_id'] == subject_id]\n",
    "\n",
    "    # Find the minimum count\n",
    "    min_count = min(len(cxr_rows), len(ecg_rows))\n",
    "\n",
    "    # Sample min_count rows from each DataFrame\n",
    "    balanced_cxr_rows = cxr_rows.sample(n=min_count, random_state=1)\n",
    "    balanced_ecg_rows = ecg_rows.sample(n=min_count, random_state=1)\n",
    "\n",
    "    # Append to the lists\n",
    "    balanced_cxr_data.append(balanced_cxr_rows)\n",
    "    balanced_ecg_data.append(balanced_ecg_rows)\n",
    "\n",
    "# Concatenate the lists into new DataFrames\n",
    "balanced_cxr_df = pd.concat(balanced_cxr_data, ignore_index=True)\n",
    "balanced_ecg_df = pd.concat(balanced_ecg_data, ignore_index=True)\n",
    "\n",
    "\n",
    "# Save the balanced DataFrames\n",
    "balanced_cxr_df.to_csv('Z:/tale2/Shared/Mohammod/physionet.org/files/mimic-cxr-jpg/2.0.0/final_mimic_cxr_metadata.csv', index=False)\n",
    "balanced_ecg_df.to_csv('Z:/tale2/Shared/Mohammod/mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0/final_mimic_ecg_metadata.csv', index=False)\n",
    "\n",
    "# Count the number of rows in each DataFrame\n",
    "num_rows_cxr = balanced_cxr_df.shape[0]\n",
    "num_rows_ecg = balanced_ecg_df.shape[0]\n",
    "\n",
    "print(f\"Number of rows in balanced MIMIC-CXR dataset: {num_rows_cxr}\")\n",
    "print(f\"Number of rows in balanced MIMIC-ECG dataset: {num_rows_ecg}\")\n",
    "\n",
    "print(\"Balancing complete. Balanced datasets saved.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T16:22:41.921714800Z",
     "start_time": "2024-01-11T16:22:22.362723400Z"
    }
   },
   "id": "355ff272a86a7030"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
